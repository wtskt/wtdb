### 第一版kv数据库
#### 写
> 接收一条数据, 遍历整个数据文件查找key是否已经存在。
> 遍历过的数据保存在一个临时文件中。
> 如果找到相同的键 就将其对应的值更新再写入临时文件。
> 如果没有找到相同的键，直接在临时文件结尾添加该键值对即可。
> 最后将临时文件中的数据重新写入数据文件，完成。

**优化思路:** 
1. 重新写入数据文件是个多余的过程，将原数据文件删除，再将临时文件改名
为数据文件可以节省不少时间

---
#### 读
> 从数据文件头部顺序往下读取，匹配每一条数据的key。
> 找到后，截取对应的值。
> 没有找到，返回NULL。

**优化思路:** 
1. 读取采用的是遍历查找的方式，在操作上似乎无可优化了，只能从结构上出发，
采用索引的方式来优化读取。

---
#### 删
> 遍历整个文件，除去要删除的kv对之外，其它数据保存至临时文件
> 最后再用临时文件的是数据覆盖掉数据文件。

**优化思路:**
1. 同写入操作





### 第二版kv数据库
#### 写
> 我们把原来将临时文件再次写入数据文件的过程取消。
> 把原数据文件删除，并将临时文件名改为数据文件。

**优化思路:**
1. 这样的写操作依然比较慢，我需要遍历整个表来确定key是否存在。
这样快速的知道数据库中有没有这个key呢？

---
#### 读
> 

---
#### 删
> 和写操作的优化类似



### 第三版kv数据库
#### 读
> 之前的查找操作是从文件头部一直查到文件末尾。
> 对于文件中的文件，我们除了顺序的访问之外，还可以进行随机访问。
> 既然如此，对于每个键值对的位置，我们想办法记住不就行了，这就需要引入索引。
> 我们可以记录每个键对应值的位置信息，
> 等查询的时候取出对应的位置信息，就可以在文件中直接找到的对应的值。
> 关于索引，应该是和每一条数据一一对应。
> 所以，索引需要和数据文件一样保存在磁盘中。
> 每次我们打开数据库的时候，将索引加载到内存，因为内存的速度比磁盘快很多。

**优化思路:**
1. 每次读取数据的速度虽然是快了，但仍有可以改进的地方。现在的读取操作，仍然是
直接从数据文件中读取，每次都要打开文件，实在是有些不尽人意。

---
#### 写
> 完成了对读取的优化，写操作也能进行相应的优化。
> 之前两个版本的数据库的写操作，是需要先确认数据文件中是否已经有
> 相应的键的，这个过程是需要进行遍历整个文件的。
> 在引入索引后，就可以在内存中的索引表中快速判断对应键是否存在了。 
> 每次新加入一个键的同时，生成一对索引。
> 并在某个时刻将内存中的索引全部flush到磁盘

**优化思路:**
1. 对于每个写操作，写入接口只能接收一条数据。即每次打开文件只能写入一条
   数据。假设我要写入一万条数据，就必须打开关闭文件一万次。单从结果上来说
   这与我打开文件一次性写入一万条数据是一样的
2. 对于数据的修改操作，采取的仍然是遍历查找的方式。 TODO


---
#### 删
**优化思路:**
1. 删除接口也只支持每次删除一个键值对。能否考虑对删除的规则进行一个改变，
   用某种方法标记删除的数据，当需要删除的数据达到一定量的时候再进行删除。